{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import threading\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision\n",
        "from torchvision.transforms import v2\n",
        "from torchvision.transforms.v2 import ToTensor\n",
        "from torchvision import datasets\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-13T16:25:35.891117Z"
        },
        "id": "jy2qISYZ1rc7"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.device_count())\n",
        "for i in range(torch.cuda.device_count()):\n",
        "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "device1 = torch.device(\"cuda:0\")\n",
        "device2 = torch.device(\"cuda:1\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-13T16:25:35.899380Z",
          "iopub.execute_input": "2025-10-13T16:25:35.899740Z",
          "iopub.status.idle": "2025-10-13T16:25:35.924278Z",
          "shell.execute_reply.started": "2025-10-13T16:25:35.899708Z",
          "shell.execute_reply": "2025-10-13T16:25:35.923251Z"
        },
        "id": "aOBayWep1rc8",
        "outputId": "8e11715f-0878-4889-e25b-11f4c60a92b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "GPU 0: Tesla T4\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = v2.Compose([\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "    v2.RandomCrop(32, padding=4),\n",
        "    v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    v2.RandomRotation(15),\n",
        "    ToTensor(),\n",
        "    v2.Normalize(\n",
        "        mean=[0.5071, 0.4867, 0.4408],\n",
        "        std=[0.2675, 0.2565, 0.2761]\n",
        "    )\n",
        "])\n",
        "transform_test = v2.Compose([\n",
        "    ToTensor(),\n",
        "    v2.Normalize(\n",
        "        mean=[0.5071, 0.4867, 0.4408],\n",
        "        std=[0.2675, 0.2565, 0.2761]\n",
        "    )\n",
        "])\n",
        "trainset = datasets.CIFAR100(root = './data', train = True, download= True, transform = transform_train)\n",
        "testset = datasets.CIFAR100(root = './data', train = False, download= True, transform = transform_test)\n",
        "\n",
        "train_size = int(0.8* len(trainset))\n",
        "valid_size = len(trainset) - train_size\n",
        "trainset, validset = random_split(trainset, [train_size, valid_size])\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size = 64, shuffle = True)\n",
        "valid_loader = DataLoader(validset, batch_size = 64, shuffle = False)\n",
        "test_loader = DataLoader(testset, batch_size = 64, shuffle = False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "fQchviof1rc8",
        "outputId": "b6688115-2232-4f42-ffed-2c78ac47bec7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "def train_dataloader_model(\n",
        "    model, train_loader, valid_loader, optim, loss_fn,\n",
        "    device=None, max_epochs=100, diff=1e-3, patience=5, scheduler = None, name = None\n",
        "):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    valid_accuracies = []\n",
        "\n",
        "    valid_loss_min = float(\"inf\")\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        # ----------------------------\n",
        "        # TRAINING PHASE\n",
        "        # ----------------------------\n",
        "        model.train()\n",
        "        running_train_loss = 0.0\n",
        "\n",
        "        for X_train, y_train in train_loader:\n",
        "            X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "\n",
        "            optim.zero_grad()\n",
        "            y_pred = model(X_train)\n",
        "            loss = loss_fn(y_pred, y_train)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            running_train_loss += loss.item()\n",
        "\n",
        "        epoch_train_loss = running_train_loss / len(train_loader)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "\n",
        "        # ----------------------------\n",
        "        # VALIDATION PHASE\n",
        "        # ----------------------------\n",
        "        model.eval()\n",
        "        running_valid_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X_valid, y_valid in valid_loader:\n",
        "                X_valid, y_valid = X_valid.to(device), y_valid.to(device)\n",
        "                y_pred = model(X_valid)\n",
        "\n",
        "                # Compute validation loss\n",
        "                loss = loss_fn(y_pred, y_valid)\n",
        "                running_valid_loss += loss.item()\n",
        "\n",
        "                # Compute accuracy\n",
        "                _, predicted = torch.max(y_pred, 1)\n",
        "                correct += (predicted == y_valid).sum().item()\n",
        "                total += y_valid.size(0)\n",
        "\n",
        "        epoch_valid_loss = running_valid_loss / len(valid_loader)\n",
        "        epoch_valid_acc = correct / total\n",
        "\n",
        "        valid_losses.append(epoch_valid_loss)\n",
        "        valid_accuracies.append(epoch_valid_acc)\n",
        "\n",
        "        scheduler.step(epoch_valid_loss)\n",
        "        # ----------------------------\n",
        "        # EARLY STOPPING CHECKS\n",
        "        # ----------------------------\n",
        "        if epoch > 0 and abs(train_losses[-1] - train_losses[-2]) < diff:\n",
        "            print(f\"{name}|epoch {epoch}: loss diff < {diff} â†’ early convergence.\")\n",
        "            break\n",
        "\n",
        "        if epoch_valid_loss < valid_loss_min - diff:\n",
        "            valid_loss_min = epoch_valid_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        print(\n",
        "            f\"{name}|Epoch [{epoch+1}/{max_epochs}] | \"\n",
        "            f\"Train Loss: {epoch_train_loss:.4f} | \"\n",
        "            f\"Valid Loss: {epoch_valid_loss:.4f} | \"\n",
        "            f\"Valid Acc: {epoch_valid_acc*100:.2f}%\"\n",
        "        )\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"\\nEarly stopping: no improvement for {patience} epochs.\")\n",
        "            break\n",
        "\n",
        "    # ----------------------------\n",
        "    # PLOTTING BEFORE RETURN\n",
        "    # ----------------------------\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, valid_losses, label=\"Valid Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training vs Validation Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, valid_accuracies, label=\"Valid Accuracy\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Validation Accuracy\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "jupyter": {
          "source_hidden": true
        },
        "id": "1XrQx7LZ1rc9"
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNeXt"
      ],
      "metadata": {
        "id": "HnOWw1xz140K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNeXtBlock(nn.Module):\n",
        "    \"\"\"The ResNeXt block.\"\"\"\n",
        "    def __init__(self,in_channels, out_channels, groups, bot_mul, use_1x1conv=False,\n",
        "                 strides=1):\n",
        "        super().__init__()\n",
        "        bot_channels = int(round(out_channels * bot_mul))\n",
        "        bot_channels = max(bot_channels, groups)\n",
        "        self.conv1 = nn.Conv2d(in_channels, bot_channels, kernel_size=1, stride=1)\n",
        "        self.bn1 = nn.BatchNorm2d(bot_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(bot_channels, bot_channels, kernel_size=3,\n",
        "                                   stride=strides, padding=1,\n",
        "                                   groups=bot_channels//groups)\n",
        "        self.bn2 = nn.BatchNorm2d(bot_channels)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(bot_channels, out_channels, kernel_size=1, stride=1)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        if use_1x1conv:\n",
        "            self.conv4 = nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
        "                                       stride=strides)\n",
        "            self.bn4 = nn.BatchNorm2d(out_channels)\n",
        "        else:\n",
        "            self.conv4 = None\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = self.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.relu(self.bn2(self.conv2(Y)))\n",
        "        Y = self.bn3(self.conv3(Y))\n",
        "        if self.conv4:\n",
        "            X = self.bn4(self.conv4(X))\n",
        "        return self.relu(Y + X)\n",
        "class ResNeXt(nn.Module):\n",
        "    def block(self, num_residuals, in_channel, out_channels,\n",
        "              groups=32, bot_mul=0.25, first_block=False):\n",
        "        blk = []\n",
        "        for i in range(num_residuals):\n",
        "            if i == 0 and not first_block:\n",
        "               blk.append(ResNeXtBlock(in_channel, out_channels,\n",
        "                                    groups, bot_mul, use_1x1conv=True, strides=2))\n",
        "            else:\n",
        "                blk.append(ResNeXtBlock(out_channels, out_channels,\n",
        "                                    groups, bot_mul))\n",
        "            in_channel = out_channels\n",
        "        return nn.Sequential(*blk)\n",
        "\n",
        "    def __init__(self, arch, num_classes=100):\n",
        "        super(ResNeXt, self).__init__()\n",
        "        self.b1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "        self.net = nn.Sequential(self.b1)\n",
        "        for i, b in enumerate(arch):\n",
        "            self.net.add_module(f'b{i+2}', self.block(*b, first_block=(i==0)))\n",
        "        self.net.add_module('last', nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "            nn.Linear(512, num_classes)))\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class ResNeXt18(ResNeXt):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super().__init__(((2, 64, 64), (2, 64, 128), (2, 128, 256), (2, 256, 512))\n",
        "                         , num_classes)\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "5jAK0KDq1rc9"
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SE_ResNeXt\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "otfnzHAP17kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, num_channels, r = 16):\n",
        "        super().__init__()\n",
        "        self.GlobalPooling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc1 = nn.Linear(num_channels, num_channels//r)\n",
        "        self.fc2 = nn.Linear(num_channels//r, num_channels)\n",
        "        self.net = nn.Sequential(\n",
        "            self.GlobalPooling,nn.Flatten(), self.fc1, nn.ReLU(), self.fc2, nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        y = self.net(x)\n",
        "        y = y[:, :, None, None]\n",
        "        return x * y\n",
        "class SE_ResNeXtBlock(ResNeXtBlock):\n",
        "    def __init__(self, in_channels, out_channels, groups, bot_mul, use_1x1conv=False,\n",
        "                 strides=1):\n",
        "        super().__init__(in_channels, out_channels, groups, bot_mul, use_1x1conv,\n",
        "                 strides)\n",
        "        self.se = SEBlock(out_channels)\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = self.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.relu(self.bn2(self.conv2(Y)))\n",
        "        Y = self.bn3(self.conv3(Y))\n",
        "        if self.conv4:\n",
        "            X = self.bn4(self.conv4(X))\n",
        "        Y = self.se(Y)\n",
        "        return self.relu(Y + X)\n",
        "class SE_ResNeXt(ResNeXt):\n",
        "    def block(self, num_residuals, in_channel, out_channels,\n",
        "              groups=32, bot_mul=0.25, first_block=False):\n",
        "        blk = []\n",
        "        for i in range(num_residuals):\n",
        "            if i == 0 and not first_block:\n",
        "               blk.append(SE_ResNeXtBlock(in_channel, out_channels,\n",
        "                                    groups, bot_mul, use_1x1conv=True, strides=2))\n",
        "            else:\n",
        "                blk.append(SE_ResNeXtBlock(out_channels, out_channels,\n",
        "                                    groups, bot_mul))\n",
        "            in_channel = out_channels\n",
        "        return nn.Sequential(*blk)\n",
        "    def __init__(self, arch, num_classes=100):\n",
        "        super().__init__(arch, num_classes)\n",
        "class SE_ResNeXt18(SE_ResNeXt):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super().__init__(((2, 64, 64), (2, 64, 128), (2, 128, 256), (2, 256, 512))\n",
        "                         , num_classes)"
      ],
      "metadata": {
        "id": "OW4_ymyx13dr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = ResNeXt18().to(device1)\n",
        "optim1 = torch.optim.Adam(model1.parameters(), lr=1e-3, weight_decay = 1e-4)\n",
        "model2 = SE_ResNeXt18().to(device2)\n",
        "optim2 = torch.optim.Adam(model2.parameters(), lr=1e-3, weight_decay = 1e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "scheduler1 = ReduceLROnPlateau(optim1, mode='min', factor=0.5, patience=3)\n",
        "scheduler2 = ReduceLROnPlateau(optim2, mode='min', factor=0.5, patience=3)"
      ],
      "metadata": {
        "trusted": true,
        "id": "px9F8pl61rc9",
        "outputId": "72b8485a-2129-44c3-c33a-0f17729fc4b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AcceleratorError",
          "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4082678871.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNeXt18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptim1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSE_ResNeXt18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0moptim2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1367\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1353\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m                     )\n\u001b[0;32m-> 1355\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1356\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "total_params1 = sum(p.numel() for p in model1.parameters())\n",
        "print(f\"Total parameters of model1: {total_params1:,}\")\n",
        "total_params2 = sum(p.numel() for p in model2.parameters())\n",
        "print(f\"Total parameters of model2: {total_params2:,}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "IbsJltfl1rc9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = threading.Thread(\n",
        "    target=train_dataloader_model,\n",
        "    args=(model1, train_loader, valid_loader),\n",
        "    kwargs={\n",
        "        'optim': optim1,\n",
        "        'loss_fn': loss_fn,\n",
        "        'scheduler': scheduler1,\n",
        "        'name': 'model1'\n",
        "    }\n",
        ")\n",
        "\n",
        "t2 = threading.Thread(\n",
        "    target=train_dataloader_model,\n",
        "    args=(model2, train_loader, valid_loader),\n",
        "    kwargs={\n",
        "        'optim': optim2,\n",
        "        'loss_fn': loss_fn,\n",
        "        'scheduler': scheduler2,\n",
        "        'name': 'model2'\n",
        "    }\n",
        ")\n",
        "t1.start()\n",
        "t2.start()\n",
        "\n",
        "t1.join()\n",
        "t2.join()"
      ],
      "metadata": {
        "id": "kIC2DCFF6thX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}